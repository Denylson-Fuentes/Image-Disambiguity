{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-lender",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "virtual-assets",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "import torchvision as tv\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "import os\n",
    "import os.path\n",
    "from torch import nn\n",
    "from torchvision.datasets.mnist import read_image_file, read_label_file\n",
    "from torchvision.datasets.utils import download_and_extract_archive, extract_archive, verify_str_arg, check_integrity\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-miami",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "overall-graham",
     "kernelId": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# class MNISTsuperimposed(VisionDataset):\n",
    "#     \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "\n",
    "#     Args:\n",
    "#         root (string): Root directory of dataset where ``MNIST/processed/training.pt``\n",
    "#             and  ``MNIST/processed/test.pt`` exist.\n",
    "#         train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "#             otherwise from ``test.pt``.\n",
    "#         download (bool, optional): If true, downloads the dataset from the internet and\n",
    "#             puts it in root directory. If dataset is already downloaded, it is not\n",
    "#             downloaded again.\n",
    "#         transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "#             and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "#         target_transform (callable, optional): A function/transform that takes in the\n",
    "#             target and transforms it.\n",
    "#     \"\"\"\n",
    "\n",
    "#     mirrors = [\n",
    "#         'http://yann.lecun.com/exdb/mnist/',\n",
    "#         'https://ossci-datasets.s3.amazonaws.com/mnist/',\n",
    "#     ]\n",
    "\n",
    "#     resources = [\n",
    "#         (\"train-images-idx3-ubyte.gz\", \"f68b3c2dcbeaaa9fbdd348bbdeb94873\"),\n",
    "#         (\"train-labels-idx1-ubyte.gz\", \"d53e105ee54ea40749a09fcbcd1e9432\"),\n",
    "#         (\"t10k-images-idx3-ubyte.gz\", \"9fb629c4189551a2d022fa330f9573f3\"),\n",
    "#         (\"t10k-labels-idx1-ubyte.gz\", \"ec29112dd5afa0611ce80d1b7f02629c\")\n",
    "#     ]\n",
    "\n",
    "#     training_file = 'training.pt'\n",
    "#     test_file = 'test.pt'\n",
    "#     classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
    "#                '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "\n",
    "#     @property\n",
    "#     def train_labels(self):\n",
    "#         warnings.warn(\"train_labels has been renamed targets\")\n",
    "#         return self.targets\n",
    "\n",
    "#     @property\n",
    "#     def test_labels(self):\n",
    "#         warnings.warn(\"test_labels has been renamed targets\")\n",
    "#         return self.targets\n",
    "\n",
    "#     @property\n",
    "#     def train_data(self):\n",
    "#         warnings.warn(\"train_data has been renamed data\")\n",
    "#         return self.data\n",
    "\n",
    "#     @property\n",
    "#     def test_data(self):\n",
    "#         warnings.warn(\"test_data has been renamed data\")\n",
    "#         return self.data\n",
    "\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             root,\n",
    "#             train= True,\n",
    "#             transform = None,\n",
    "#             target_transform = None,\n",
    "#             download = False,\n",
    "#     ):\n",
    "#         super(MNISTsuperimposed, self).__init__(root, transform=transform,\n",
    "#                                     target_transform=target_transform)\n",
    "#         self.train = train  # training set or test set\n",
    "\n",
    "#         if self._check_legacy_exist():\n",
    "#             self.data, self.targets = self._load_legacy_data()\n",
    "\n",
    "#         if download:\n",
    "#             self.download()\n",
    "\n",
    "#         if not self._check_exists():\n",
    "#             raise RuntimeError('Dataset not found.' +\n",
    "#                                ' You can use download=True to download it')\n",
    "\n",
    "#         self.data, self.targets = self._load_data()\n",
    "\n",
    "#     def _check_legacy_exist(self):\n",
    "#         processed_folder_exists = os.path.exists(self.processed_folder)\n",
    "#         if not processed_folder_exists:\n",
    "#             return False\n",
    "\n",
    "#         return all(\n",
    "#             check_integrity(os.path.join(self.processed_folder, file)) for file in (self.training_file, self.test_file)\n",
    "#         )\n",
    "\n",
    "#     def _load_legacy_data(self):\n",
    "#         # This is for BC only. We no longer cache the data in a custom binary, but simply read from the raw data\n",
    "#         # directly.\n",
    "#         data_file = self.training_file if self.train else self.test_file\n",
    "#         return torch.load(os.path.join(self.processed_folder, data_file))\n",
    "\n",
    "#     def _load_data(self):\n",
    "#         image_file = f\"{'train' if self.train else 't10k'}-images-idx3-ubyte\"\n",
    "#         data = read_image_file(os.path.join(self.raw_folder, image_file))\n",
    "#         #Technically, we do not even need the labels for now\n",
    "#         # We just need the clean images of both types\n",
    "#         randata = data[torch.randperm(data.shape[0]),:,:]\n",
    "#         targets = (data, randata)\n",
    "        \n",
    "        \n",
    "#         # Now do the ambiguation here\n",
    "#         data = data + randata\n",
    "#         return data, targets\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             index (int): Index\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: (image, target) where target is index of the target class.\n",
    "#         \"\"\"\n",
    "#         img, target = self.data[index], (self.targets[0][index], self.targets[1][index])\n",
    "#         # doing this so that it is consistent with all other datasets\n",
    "#         # to return a PIL Imagedata[torch.randperm(data.shape[0]),:,:]\n",
    "#         img = Image.fromarray(img.numpy(), mode='L')\n",
    "#         tgt1 = Image.fromarray(target[0].numpy(), mode='L')\n",
    "#         tgt2 = Image.fromarray(target[1].numpy(), mode='L')\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             img = self.transform(img)\n",
    "\n",
    "#         if self.target_transform is not None:\n",
    "#             tgt1 = self.target_transform(tgt1)\n",
    "#             tgt2 = self.target_transform(tgt2)\n",
    "            \n",
    "\n",
    "#         return img, (tgt1, tgt2)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     @property\n",
    "#     def raw_folder(self):\n",
    "#         return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
    "\n",
    "#     @property\n",
    "#     def processed_folder(self) -> str:\n",
    "#         return os.path.join(self.root, self.__class__.__name__, 'processed')\n",
    "\n",
    "#     @property\n",
    "#     def class_to_idx(self):\n",
    "#         return {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "#     def _check_exists(self):\n",
    "#         return all(\n",
    "#             check_integrity(os.path.join(self.raw_folder, os.path.splitext(os.path.basename(url))[0]))\n",
    "#             for url, _ in self.resources\n",
    "#         )\n",
    "\n",
    "#     def download(self):\n",
    "#         \"\"\"Download the MNIST data if it doesn't exist already.\"\"\"\n",
    "\n",
    "#         if self._check_exists():\n",
    "#             return\n",
    "\n",
    "#         os.makedirs(self.raw_folder, exist_ok=True)\n",
    "\n",
    "#         # download files\n",
    "#         for filename, md5 in self.resources:\n",
    "#             for mirror in self.mirrors:\n",
    "#                 url = \"{}{}\".format(mirror, filename)\n",
    "#                 try:\n",
    "#                     print(\"Downloading {}\".format(url))\n",
    "#                     download_and_extract_archive(\n",
    "#                         url, download_root=self.raw_folder,\n",
    "#                         filename=filename,\n",
    "#                         md5=md5\n",
    "#                     )\n",
    "#                 except URLError as error:\n",
    "#                     print(\n",
    "#                         \"Failed to download (trying next):\\n{}\".format(error)\n",
    "#                     )\n",
    "#                     continue\n",
    "#                 finally:\n",
    "#                     print()\n",
    "#                 break\n",
    "#             else:\n",
    "#                 raise RuntimeError(\"Error downloading {}\".format(filename))\n",
    "\n",
    "#     def extra_repr(self) -> str:\n",
    "#         return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-reset",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "another-shell",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "class MNISTsuperimposed(VisionDataset):\n",
    "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``MNIST/processed/training.pt``\n",
    "            and  ``MNIST/processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "\n",
    "    mirrors = [\n",
    "        'http://yann.lecun.com/exdb/mnist/',\n",
    "        'https://ossci-datasets.s3.amazonaws.com/mnist/',\n",
    "    ]\n",
    "\n",
    "    resources = [\n",
    "        (\"train-images-idx3-ubyte.gz\", \"f68b3c2dcbeaaa9fbdd348bbdeb94873\"),\n",
    "        (\"train-labels-idx1-ubyte.gz\", \"d53e105ee54ea40749a09fcbcd1e9432\"),\n",
    "        (\"t10k-images-idx3-ubyte.gz\", \"9fb629c4189551a2d022fa330f9573f3\"),\n",
    "        (\"t10k-labels-idx1-ubyte.gz\", \"ec29112dd5afa0611ce80d1b7f02629c\")\n",
    "    ]\n",
    "\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
    "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "\n",
    "    @property\n",
    "    def train_labels(self):\n",
    "        warnings.warn(\"train_labels has been renamed targets\")\n",
    "        return self.targets\n",
    "\n",
    "    @property\n",
    "    def test_labels(self):\n",
    "        warnings.warn(\"test_labels has been renamed targets\")\n",
    "        return self.targets\n",
    "\n",
    "    @property\n",
    "    def train_data(self):\n",
    "        warnings.warn(\"train_data has been renamed data\")\n",
    "        return self.data\n",
    "\n",
    "    @property\n",
    "    def test_data(self):\n",
    "        warnings.warn(\"test_data has been renamed data\")\n",
    "        return self.data\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            train= True,\n",
    "            transform = None,\n",
    "            target_transform = None,\n",
    "            download = False,\n",
    "    ):\n",
    "        super(MNISTsuperimposed, self).__init__(root, transform=transform,\n",
    "                                    target_transform=target_transform)\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if self._check_legacy_exist():\n",
    "            self.data, self.targets, self.targets = self._load_legacy_data()\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        self.data, self.targets = self._load_data()\n",
    "        \n",
    "    def _check_legacy_exist(self):\n",
    "        processed_folder_exists = os.path.exists(self.processed_folder)\n",
    "        if not processed_folder_exists:\n",
    "            return False\n",
    "\n",
    "        return all(\n",
    "            check_integrity(os.path.join(self.processed_folder, file)) for file in (self.training_file, self.test_file)\n",
    "        )\n",
    "\n",
    "    def _load_legacy_data(self):\n",
    "        # This is for BC only. We no longer cache the data in a custom binary, but simply read from the raw data\n",
    "        # directly.\n",
    "        data_file = self.training_file if self.train else self.test_file\n",
    "        return torch.load(os.path.join(self.processed_folder, data_file))\n",
    "\n",
    "    def _load_data(self):\n",
    "        image_file = f\"{'train' if self.train else 't10k'}-images-idx3-ubyte\"\n",
    "        data = read_image_file(os.path.join(self.raw_folder, image_file))\n",
    "        #Technically, we do not even need the labels for now\n",
    "        # We just need the clean images of both types\n",
    "        randata = data[torch.randperm(data.shape[0]),:,:]\n",
    "        targets = (data, randata)\n",
    "        \n",
    "        \n",
    "        # Now do the ambiguation here\n",
    "        data1 = data + randata\n",
    "        targets = (data1, data, randata)\n",
    "        return data1, targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], (self.targets[0][index], self.targets[1][index], self.targets[2][index])\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Imagedata[torch.randperm(data.shape[0]),:,:]\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "        target0 = Image.fromarray(target[0].numpy(), mode='L')\n",
    "        target1 = Image.fromarray(target[1].numpy(), mode='L')\n",
    "        target2 = Image.fromarray(target[2].numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = (self.target_transform[0](target0), self.target_transform[1](target0), self.target_transform[1](target1), self.target_transform[1](target2))\n",
    "            \n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'processed')\n",
    "\n",
    "    @property\n",
    "    def class_to_idx(self):\n",
    "        return {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return all(\n",
    "            check_integrity(os.path.join(self.raw_folder, os.path.splitext(os.path.basename(url))[0]))\n",
    "            for url, _ in self.resources\n",
    "        )\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the MNIST data if it doesn't exist already.\"\"\"\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        os.makedirs(self.raw_folder, exist_ok=True)\n",
    "\n",
    "        # download files\n",
    "        for filename, md5 in self.resources:\n",
    "            for mirror in self.mirrors:\n",
    "                url = \"{}{}\".format(mirror, filename)\n",
    "                try:\n",
    "                    print(\"Downloading {}\".format(url))\n",
    "                    download_and_extract_archive(\n",
    "                        url, download_root=self.raw_folder,\n",
    "                        filename=filename,\n",
    "                        md5=md5\n",
    "                    )\n",
    "                except URLError as error:\n",
    "                    print(\n",
    "                        \"Failed to download (trying next):\\n{}\".format(error)\n",
    "                    )\n",
    "                    continue\n",
    "                finally:\n",
    "                    print()\n",
    "                break\n",
    "            else:\n",
    "                raise RuntimeError(\"Error downloading {}\".format(filename))\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-exploration",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "surgical-dominant",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "class AddGaussNoise(object):\n",
    "    def __init__(self, mean=0, std=0.001):\n",
    "        self.std=std\n",
    "        self.mean=mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "#         print(tensor + torch.randn(tensor.size()) * self.std + self.mean)\n",
    "        return torch.tensor(random_noise(tensor,mean=self.mean,var=self.std))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__+'(mean={0},std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-mining",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "continuous-diabetes",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "class Downsample(object):\n",
    "    def __init__(self, size=[1,196]):\n",
    "        self.size=size\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        img = np.squeeze(tensor)\n",
    "        m = torch.nn.AvgPool2d(2, stride=2)\n",
    "        return m(img.unsqueeze(0))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__+'({})'.format(self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-medicaid",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "sought-perfume",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:137.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     Downsample(),\n",
    "     Downsample(),\n",
    "     AddGaussNoise(0,1e-2)\n",
    "     ])\n",
    "target1_transform= transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     Downsample(),\n",
    "     Downsample(),\n",
    "     ])\n",
    "target2_transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     ])\n",
    "\n",
    "target_transform = [target1_transform, target2_transform]\n",
    "mnist_superimposed = MNISTsuperimposed(\"./MNIST data/train\", train = True, download = True, transform = transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-senator",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "reasonable-calibration",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch = 32\n",
    "trainset = DataLoader(mnist_superimposed, batch_size=batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-broad",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "communist-grant",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "def show_images(dataset, training = True):\n",
    "    \n",
    "    fig = plt.figure(figsize = (20, 14))\n",
    "    rows = 5\n",
    "    columns = 4\n",
    "    j=0\n",
    "    for i in range(1,columns*rows+1):\n",
    "        \n",
    "        if i >=1 and i<5:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(dataset[i][0].squeeze(0), cmap='gray')\n",
    "            \n",
    "        if i >=5 and i<9:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(dataset[i-4][1][0].squeeze(0), cmap='gray')\n",
    "            \n",
    "        if i >=9 and i < 13:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(dataset[i-8][1][1].squeeze(0), cmap='gray')\n",
    "            \n",
    "        if i >= 13 and i<17:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(dataset[i-12][1][2].squeeze(0), cmap='gray')\n",
    "        \n",
    "        if i >= 17 and i<21:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(dataset[i-16][1][3].squeeze(0), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-atlas",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "sweet-armenia",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1008 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(mnist_superimposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-gather",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "animal-jewelry",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import Conv2d, ConvTranspose2d, Linear, Sequential, Flatten, ReLU, LeakyReLU, AvgPool2d, MaxPool2d,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-copying",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "endless-logic",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, inplace = False):\n",
    "        super(AE,self).__init__()\n",
    "        \n",
    "        self.Upsample_1 = nn.Sequential(\n",
    "            nn.Flatten(start_dim = 2),\n",
    "            nn.Linear(49, 64),\n",
    "            nn.Linear(64, 144),\n",
    "            nn.Linear(144, 144),\n",
    "            nn.ReLU(inplace),\n",
    "            \n",
    "            nn.Linear(144, 256),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.Linear(512, 784),\n",
    "            nn.Linear(784, 784),\n",
    "            nn.ReLU(inplace),\n",
    "        )\n",
    "        \n",
    "            \n",
    "        self.initial_Processing = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 128, kernel_size = 3, padding = 1, stride = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = 3, padding =1, stride = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace),\n",
    "        )\n",
    "\n",
    "        self.Down_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 512, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Down_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 256, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.Down_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Down_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Up_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 64, out_channels = 128, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 64, out_channels = 256, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 64, out_channels = 512, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1024, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 64, out_channels = 2, kernel_size = (1, 1))\n",
    "        )\n",
    "        \n",
    "        self.Upsample_2 = nn.Sequential(\n",
    "            nn.Flatten(start_dim = 1),\n",
    "            nn.Linear(392, 512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(inplace),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.Linear(1024, 1568),\n",
    "            nn.Linear(1568, 1568),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #First Dip\n",
    "        output = self.Upsample_1(x)\n",
    "        output = output.reshape(output.shape[0], 1, 28, 28)\n",
    "#         print(output.shape)\n",
    "        \n",
    "        output = self.initial_Processing(output)\n",
    "#         print(output.shape)\n",
    "        \n",
    "        output = self.Down_1(output)\n",
    "        output_1 = output\n",
    "#         print(output.shape)\n",
    "        \n",
    "        \n",
    "        output = self.Down_2(output)\n",
    "        output_2 = output\n",
    "#         print(output.shape)\n",
    "        \n",
    "        output = self.Down_3(output)\n",
    "        output_3 = output\n",
    "#         print(output.shape)\n",
    "        \n",
    "        output = self.Down_4(output)\n",
    "        output_4 = output\n",
    "#         print(output.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        output = self.Up_1(output)\n",
    "#         print(\"After Up1\", output.shape)\n",
    "        diffY = output_4.size()[2] - output.size()[2]\n",
    "        diffX = output_4.size()[3] - output.size()[3]\n",
    "        output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        output = torch.cat([output_4, output], dim=1)\n",
    "        \n",
    "\n",
    "        output = self.Up_2(output)\n",
    "#         print(\"After Up2\",output.shape)\n",
    "        diffY = output_3.size()[2] - output.size()[2]\n",
    "        diffX = output_3.size()[3] - output.size()[3]\n",
    "        output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        output = torch.cat([output_3, output], dim=1)\n",
    "\n",
    "\n",
    "        output = self.Up_3(output)\n",
    "#         print(\"After Up3\",output.shape)\n",
    "        diffY = output_2.size()[2] - output.size()[2]\n",
    "        diffX = output_2.size()[3] - output.size()[3]\n",
    "        output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        output = torch.cat([output_2, output], dim=1)\n",
    "\n",
    "\n",
    "        output = self.Up_4(output)\n",
    "#         print(\"After Up4\",output.shape)\n",
    "        diffY = output_1.size()[2] - output.size()[2]\n",
    "        diffX = output_1.size()[3] - output.size()[3]\n",
    "        output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        output = torch.cat([output_1, output], dim=1)\n",
    "\n",
    "\n",
    "        output = self.Up_5(output)\n",
    "#         print(output.shape)\n",
    "\n",
    "        \n",
    "        output = self.Upsample_2[:2](output)\n",
    "        output = self.Upsample_2[3:6](output + self.Upsample_2[2](output))\n",
    "        output = self.Upsample_2[7](output + self.Upsample_2[6](output))\n",
    "                \n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-shell",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "statewide-gender",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "AEnet = AE(inplace = True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-waterproof",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "consolidated-threshold",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(AEnet.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-allocation",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "gorgeous-eclipse",
     "kernelId": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test(AEnet, dataset, Training = True):\n",
    "\n",
    "    if Training:\n",
    "        epochs = 50\n",
    "        train_loss = []\n",
    "        t_loss = []\n",
    "        flag = True\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(dataset):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = AEnet(data[0].float().to(device))\n",
    "                output_1 = outputs[:, :784]\n",
    "                output_2 = outputs[:, 784:]\n",
    "                loss = criterion(output_1.float().to(device), torch.flatten(data[1][2],1).float().to(device)) + criterion(output_2.float().to(device), torch.flatten(data[1][3],1).float().to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss.append(loss.item())\n",
    "                running_loss += loss.item()\n",
    "                if i % 400 == 399:\n",
    "                    print('[%d, %5d] loss per image: %.6f' %\n",
    "                          (epoch + 1, i + 1, loss.item()/32))\n",
    "                    t_loss.append(loss.item()/32)\n",
    "                \n",
    "            \n",
    "\n",
    "            \n",
    "        print(\"The lowest was: \", min(train_loss)/32)\n",
    "\n",
    "        print('Finished Training')\n",
    "        flag = False\n",
    "        return outputs, data, t_loss\n",
    "            \n",
    "    else:\n",
    "        testing_loss = []\n",
    "        t_loss = []\n",
    "        for i, data in enumerate(dataset):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = AEnet(data[0].float().to(device))\n",
    "                output_1 = outputs[:, :784]\n",
    "                output_2 = outputs[:, 784:]\n",
    "                loss = criterion(output_1.float().to(device), torch.flatten(data[1][2],1).float().to(device)) + criterion(output_2.float().to(device), torch.flatten(data[1][3],1).float().to(device))\n",
    "                testing_loss.append(loss.item())\n",
    "                if i % 50 == 49:\n",
    "                    print('[%5d] loss per image: %.6f' %\n",
    "                          (i + 1, loss.item()/32))\n",
    "                    t_loss.append(loss.item()/32)\n",
    "                    \n",
    "        print(\"The lowest was: \", min(testing_loss)/32)\n",
    "        print('Finished Testing')\n",
    "        return outputs,data, t_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-karaoke",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "assigned-convention",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] loss per image: 0.003787\n",
      "[1,   800] loss per image: 0.004041\n",
      "[1,  1200] loss per image: 0.004147\n",
      "[1,  1600] loss per image: 0.004054\n",
      "[2,   400] loss per image: 0.003957\n",
      "[2,   800] loss per image: 0.004052\n",
      "[2,  1200] loss per image: 0.003675\n",
      "[2,  1600] loss per image: 0.004099\n",
      "[3,   400] loss per image: 0.003693\n",
      "[3,   800] loss per image: 0.003732\n",
      "[3,  1200] loss per image: 0.003891\n",
      "[3,  1600] loss per image: 0.003841\n",
      "[4,   400] loss per image: 0.003993\n",
      "[4,   800] loss per image: 0.003700\n",
      "[4,  1200] loss per image: 0.003642\n",
      "[4,  1600] loss per image: 0.003707\n",
      "[5,   400] loss per image: 0.004032\n",
      "[5,   800] loss per image: 0.003893\n",
      "[5,  1200] loss per image: 0.003669\n",
      "[5,  1600] loss per image: 0.003860\n",
      "[6,   400] loss per image: 0.003735\n",
      "[6,   800] loss per image: 0.003739\n",
      "[6,  1200] loss per image: 0.003759\n",
      "[6,  1600] loss per image: 0.003550\n",
      "[7,   400] loss per image: 0.003334\n",
      "[7,   800] loss per image: 0.003534\n",
      "[7,  1200] loss per image: 0.003604\n",
      "[7,  1600] loss per image: 0.003469\n",
      "[8,   400] loss per image: 0.003524\n",
      "[8,   800] loss per image: 0.003621\n",
      "[8,  1200] loss per image: 0.003732\n",
      "[8,  1600] loss per image: 0.003699\n",
      "[9,   400] loss per image: 0.003666\n",
      "[9,   800] loss per image: 0.003464\n",
      "[9,  1200] loss per image: 0.003558\n",
      "[9,  1600] loss per image: 0.003692\n",
      "[10,   400] loss per image: 0.003437\n",
      "[10,   800] loss per image: 0.003580\n",
      "[10,  1200] loss per image: 0.003844\n",
      "[10,  1600] loss per image: 0.003463\n",
      "[11,   400] loss per image: 0.003444\n",
      "[11,   800] loss per image: 0.003439\n",
      "[11,  1200] loss per image: 0.003565\n",
      "[11,  1600] loss per image: 0.003475\n",
      "[12,   400] loss per image: 0.003618\n",
      "[12,   800] loss per image: 0.003677\n",
      "[12,  1200] loss per image: 0.003546\n",
      "[12,  1600] loss per image: 0.003474\n",
      "[13,   400] loss per image: 0.003669\n",
      "[13,   800] loss per image: 0.003547\n",
      "[13,  1200] loss per image: 0.003480\n",
      "[13,  1600] loss per image: 0.003421\n",
      "[14,   400] loss per image: 0.003406\n",
      "[14,   800] loss per image: 0.003276\n",
      "[14,  1200] loss per image: 0.003455\n",
      "[14,  1600] loss per image: 0.003511\n",
      "[15,   400] loss per image: 0.003261\n",
      "[15,   800] loss per image: 0.003634\n",
      "[15,  1200] loss per image: 0.003419\n",
      "[15,  1600] loss per image: 0.003648\n",
      "[16,   400] loss per image: 0.003661\n",
      "[16,   800] loss per image: 0.003455\n",
      "[16,  1200] loss per image: 0.003403\n",
      "[16,  1600] loss per image: 0.003500\n",
      "[17,   400] loss per image: 0.003353\n",
      "[17,   800] loss per image: 0.003475\n",
      "[17,  1200] loss per image: 0.003474\n",
      "[17,  1600] loss per image: 0.003705\n",
      "[18,   400] loss per image: 0.003677\n",
      "[18,   800] loss per image: 0.003359\n",
      "[18,  1200] loss per image: 0.003339\n",
      "[18,  1600] loss per image: 0.003623\n",
      "[19,   400] loss per image: 0.003329\n",
      "[19,   800] loss per image: 0.003554\n",
      "[19,  1200] loss per image: 0.003043\n",
      "[19,  1600] loss per image: 0.003519\n",
      "[20,   400] loss per image: 0.003182\n",
      "[20,   800] loss per image: 0.003801\n",
      "[20,  1200] loss per image: 0.003386\n",
      "[20,  1600] loss per image: 0.003500\n",
      "[21,   400] loss per image: 0.003710\n",
      "[21,   800] loss per image: 0.003457\n",
      "[21,  1200] loss per image: 0.003660\n",
      "[21,  1600] loss per image: 0.003238\n",
      "[22,   400] loss per image: 0.003545\n",
      "[22,   800] loss per image: 0.003353\n",
      "[22,  1200] loss per image: 0.003467\n",
      "[22,  1600] loss per image: 0.003534\n",
      "[23,   400] loss per image: 0.003416\n",
      "[23,   800] loss per image: 0.003224\n",
      "[23,  1200] loss per image: 0.003756\n",
      "[23,  1600] loss per image: 0.003448\n",
      "[24,   400] loss per image: 0.003747\n",
      "[24,   800] loss per image: 0.003433\n",
      "[24,  1200] loss per image: 0.003231\n",
      "[24,  1600] loss per image: 0.003298\n",
      "[25,   400] loss per image: 0.003460\n",
      "[25,   800] loss per image: 0.003466\n",
      "[25,  1200] loss per image: 0.003618\n",
      "[25,  1600] loss per image: 0.003485\n",
      "[26,   400] loss per image: 0.003727\n",
      "[26,   800] loss per image: 0.003415\n",
      "[26,  1200] loss per image: 0.003326\n",
      "[26,  1600] loss per image: 0.003448\n",
      "[27,   400] loss per image: 0.003384\n",
      "[27,   800] loss per image: 0.003472\n",
      "[27,  1200] loss per image: 0.003593\n",
      "[27,  1600] loss per image: 0.003323\n",
      "[28,   400] loss per image: 0.003236\n",
      "[28,   800] loss per image: 0.003310\n",
      "[28,  1200] loss per image: 0.003366\n",
      "[28,  1600] loss per image: 0.003226\n",
      "[29,   400] loss per image: 0.003422\n",
      "[29,   800] loss per image: 0.003476\n",
      "[29,  1200] loss per image: 0.003617\n",
      "[29,  1600] loss per image: 0.003314\n",
      "[30,   400] loss per image: 0.003515\n",
      "[30,   800] loss per image: 0.003297\n",
      "[30,  1200] loss per image: 0.003267\n",
      "[30,  1600] loss per image: 0.003470\n",
      "[31,   400] loss per image: 0.003234\n",
      "[31,   800] loss per image: 0.003190\n",
      "[31,  1200] loss per image: 0.003451\n",
      "[31,  1600] loss per image: 0.003516\n",
      "[32,   400] loss per image: 0.003627\n",
      "[32,   800] loss per image: 0.003538\n",
      "[32,  1200] loss per image: 0.003350\n",
      "[32,  1600] loss per image: 0.003443\n",
      "[33,   400] loss per image: 0.003472\n",
      "[33,   800] loss per image: 0.003314\n",
      "[33,  1200] loss per image: 0.003310\n",
      "[33,  1600] loss per image: 0.003314\n",
      "[34,   400] loss per image: 0.003237\n",
      "[34,   800] loss per image: 0.003086\n",
      "[34,  1200] loss per image: 0.003369\n",
      "[34,  1600] loss per image: 0.003345\n",
      "[35,   400] loss per image: 0.003247\n",
      "[35,   800] loss per image: 0.003538\n",
      "[35,  1200] loss per image: 0.003082\n",
      "[35,  1600] loss per image: 0.003452\n",
      "[36,   400] loss per image: 0.003242\n",
      "[36,   800] loss per image: 0.003322\n",
      "[36,  1200] loss per image: 0.003493\n",
      "[36,  1600] loss per image: 0.003356\n"
     ]
    }
   ],
   "source": [
    "output, train_data, train_loss= train_test(AEnet, trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-honey",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "aggressive-measurement",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#Print only the output images\n",
    "def show_output_images(outputs):\n",
    "    \n",
    "    fig = plt.figure(figsize = (20, 14))\n",
    "    rows = 5\n",
    "    columns = 4\n",
    "    j=0\n",
    "    for i in range(1,columns*rows+1):\n",
    "        if i >=1 and i < 5:    \n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(outputs[i][:784].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "        if i >=5 and i < 9:    \n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(outputs[i-4][784:].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-penetration",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "suspended-kitty",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "show_output_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-samba",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "respected-investment",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#Print only the input images\n",
    "def show_input_images(inputs):\n",
    "    \n",
    "    fig = plt.figure(figsize = (20, 14))\n",
    "    rows = 5\n",
    "    columns = 4\n",
    "    j=0\n",
    "    for i in range(1,columns*rows+1):\n",
    "        # Denoising\n",
    "        if i >=1 and i< 5:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(inputs[0][i].cpu().detach().numpy().reshape(7,7), cmap='gray')\n",
    "            \n",
    "        #Upsampling\n",
    "        if i >=5 and i< 9:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(inputs[1][0][i-4].cpu().detach().numpy().reshape(7,7), cmap='gray')\n",
    "            \n",
    "        #Disambiguation\n",
    "        if i >= 9 and i < 13:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(inputs[1][1][i-8].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "        \n",
    "        if i >= 13 and i < 17:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(inputs[1][2][i-12].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "        \n",
    "        if i >= 17 and i < 21:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(inputs[1][3][i-16].cpu().detach().numpy().reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-primary",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "olive-europe",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "show_input_images(inputs=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-shareware",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "mineral-greenhouse",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "testing_superimposed = MNISTsuperimposed(\"./MNIST data/train\", train = False, download = True, transform = transform, target_transform=target_transform)\n",
    "testset = DataLoader(testing_superimposed, batch_size=32, shuffle = False)\n",
    "outputs, test_data, test_loss = train_test(AEnet, testset, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-drill",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "infrared-neighborhood",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "show_output_images(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-scene",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "imperial-clearing",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "show_input_images(inputs=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-middle",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "atmospheric-registration",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#Print only the output images\n",
    "def show_output_images(dataset, outputs):\n",
    "    \n",
    "    fig = plt.figure(figsize = (20, 35))\n",
    "    rows = 7\n",
    "    columns = 4\n",
    "    offset = -1\n",
    "    \n",
    "    for i in range(1,columns*rows+1):\n",
    "        if i >=1 and i< 5:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.axis('off')\n",
    "            plt.title('True Image')\n",
    "            if i == 1:\n",
    "                plt.imshow(dataset[1][2][1].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 2:\n",
    "                plt.imshow(dataset[1][2][2].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 3:\n",
    "                plt.imshow(dataset[1][2][7].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 4:\n",
    "                plt.imshow(dataset[1][2][14].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(dataset[1][2][i + offset].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "        if i >=5 and i< 9:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"True Image\")\n",
    "            if i == 5:\n",
    "                plt.imshow(dataset[1][3][1].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 6:\n",
    "                plt.imshow(dataset[1][3][2].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 7:\n",
    "                plt.imshow(dataset[1][3][7].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 8:\n",
    "                plt.imshow(dataset[1][3][14].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(dataset[1][3][i-4 + offset].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "        if i >=9 and i < 13:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Superimposed\")\n",
    "            if i == 9:\n",
    "                plt.imshow(dataset[1][1][1].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 10:\n",
    "                plt.imshow(dataset[1][1][2].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 11:\n",
    "                plt.imshow(dataset[1][1][7].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 12:\n",
    "                plt.imshow(dataset[1][1][14].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(dataset[1][1][i-8 + offset].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "        if i >=13 and i < 17:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Downsampled\")\n",
    "            if i == 13:\n",
    "                plt.imshow(dataset[1][0][1].squeeze(0), cmap='gray')\n",
    "            elif i == 14:\n",
    "                plt.imshow(dataset[1][0][2].squeeze(0), cmap='gray')\n",
    "            elif i == 15:\n",
    "                plt.imshow(dataset[1][0][7].squeeze(0), cmap='gray')\n",
    "            elif i == 16:\n",
    "                plt.imshow(dataset[1][0][14].squeeze(0), cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(dataset[1][0][i-12 + offset].squeeze(0), cmap = 'gray')\n",
    "        if i >=17 and i < 21:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Noisy\")\n",
    "            if i == 17:\n",
    "                plt.imshow(dataset[0][1].squeeze(0), cmap='gray')\n",
    "            elif i == 18:\n",
    "                plt.imshow(dataset[0][2].squeeze(0), cmap='gray')\n",
    "            elif i == 19:\n",
    "                plt.imshow(dataset[0][7].squeeze(0), cmap='gray')\n",
    "            elif i == 20:\n",
    "                plt.imshow(dataset[0][14].squeeze(0), cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(dataset[0][i-16 + offset].squeeze(0), cmap = 'gray')\n",
    "        if i >=21 and i < 25:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.title(\"Recon Image\")\n",
    "            if i == 21:\n",
    "                mse = criterion(outputs[1][:784].float().to(device), torch.flatten(dataset[1][2],1).float().to(device))\n",
    "                plt.xlabel('MSE: {:.6f}'.format(mse/32))\n",
    "                plt.imshow(outputs[1][:784].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 22:\n",
    "                mse = criterion(outputs[2][:784].float().to(device), torch.flatten(dataset[1][2],1).float().to(device))\n",
    "                plt.xlabel('MSE: {:.6f}'.format(mse/32))\n",
    "                plt.imshow(outputs[2][:784].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 23:\n",
    "                mse = criterion(outputs[7][:784].float().to(device), torch.flatten(dataset[1][2],1).float().to(device))\n",
    "                plt.xlabel('MSE: {:.6f}'.format(mse/32))\n",
    "                plt.imshow(outputs[7][:784].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 24:\n",
    "                mse = criterion(outputs[14][:784].float().to(device), torch.flatten(dataset[1][2],1).float().to(device))\n",
    "                plt.xlabel('MSE: {:.6f}'.format(mse/32))\n",
    "                plt.imshow(outputs[14][:784].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(outputs[i-20 + offset][:784].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "        if i >=25 and i < 29:    \n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.title(\"Recon Image\")\n",
    "            if i == 25:\n",
    "                mse = criterion(outputs[1][784:].float().to(device), torch.flatten(dataset[1][3],1).float().to(device))\n",
    "                plt.xlabel('MSE: {:.6f}'.format(mse/32))\n",
    "                plt.imshow(outputs[1][784:].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 26:\n",
    "                mse = criterion(outputs[2][784:].float().to(device), torch.flatten(dataset[1][3],1).float().to(device))\n",
    "                plt.xlabel('MSE: {:.6f}'.format(mse/32))\n",
    "                plt.imshow(outputs[2][784:].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 27:\n",
    "                mse = criterion(outputs[7][784:].float().to(device), torch.flatten(dataset[1][3],1).float().to(device))\n",
    "                plt.xlabel('MSE: {:.6f}'.format(mse/32))\n",
    "                plt.imshow(outputs[7][784:].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            elif i == 28:\n",
    "                mse = criterion(outputs[14][784:].float().to(device), torch.flatten(dataset[1][3],1).float().to(device))\n",
    "                plt.xlabel('MSE: {:.6f}'.format(mse/32))\n",
    "                plt.imshow(outputs[14][784:].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(outputs[i-24 + offset][784:].cpu().detach().numpy().reshape(28,28), cmap='gray')\n",
    "\n",
    "    plt.savefig('AE_with_Noise_1e-2_4xDownsampled.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-chambers",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "positive-priest",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "show_output_images(test_data, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-holder",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "dominican-mandate",
     "kernelId": ""
    }
   },
   "source": [
    "## Loss Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-savage",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "hydraulic-perry",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(loss):\n",
    "    fig = plt.figure(figsize = (10, 7))\n",
    "    x = list(np.arange(0.0, 50.0, 0.25))\n",
    "    plt.axis(\"on\")\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.plot(x, loss)\n",
    "    plt.savefig('AE_with_Noise_1e-2_4xDownsampled_plot_loss.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-class",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "under-clearance",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_loss(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-skill",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "curious-groove",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-beach",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "twenty-statement",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
