{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-design",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "import torchvision as tv\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "import os\n",
    "import os.path\n",
    "from torch import nn\n",
    "from torchvision.datasets.mnist import read_image_file, read_label_file\n",
    "from torchvision.datasets.utils import download_and_extract_archive, extract_archive, verify_str_arg, check_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-confidence",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "class MNISTsuperimposed(VisionDataset):\n",
    "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``MNIST/processed/training.pt``\n",
    "            and  ``MNIST/processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "\n",
    "    mirrors = [\n",
    "        'http://yann.lecun.com/exdb/mnist/',\n",
    "        'https://ossci-datasets.s3.amazonaws.com/mnist/',\n",
    "    ]\n",
    "\n",
    "    resources = [\n",
    "        (\"train-images-idx3-ubyte.gz\", \"f68b3c2dcbeaaa9fbdd348bbdeb94873\"),\n",
    "        (\"train-labels-idx1-ubyte.gz\", \"d53e105ee54ea40749a09fcbcd1e9432\"),\n",
    "        (\"t10k-images-idx3-ubyte.gz\", \"9fb629c4189551a2d022fa330f9573f3\"),\n",
    "        (\"t10k-labels-idx1-ubyte.gz\", \"ec29112dd5afa0611ce80d1b7f02629c\")\n",
    "    ]\n",
    "\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
    "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "\n",
    "    @property\n",
    "    def train_labels(self):\n",
    "        warnings.warn(\"train_labels has been renamed targets\")\n",
    "        return self.targets\n",
    "\n",
    "    @property\n",
    "    def test_labels(self):\n",
    "        warnings.warn(\"test_labels has been renamed targets\")\n",
    "        return self.targets\n",
    "\n",
    "    @property\n",
    "    def train_data(self):\n",
    "        warnings.warn(\"train_data has been renamed data\")\n",
    "        return self.data\n",
    "\n",
    "    @property\n",
    "    def test_data(self):\n",
    "        warnings.warn(\"test_data has been renamed data\")\n",
    "        return self.data\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            train= True,\n",
    "            transform = None,\n",
    "            target_transform = None,\n",
    "            download = False,\n",
    "    ):\n",
    "        super(MNISTsuperimposed, self).__init__(root, transform=transform,\n",
    "                                    target_transform=target_transform)\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if self._check_legacy_exist():\n",
    "            self.data, self.targets = self._load_legacy_data()\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        self.data, self.targets = self._load_data()\n",
    "\n",
    "    def _check_legacy_exist(self):\n",
    "        processed_folder_exists = os.path.exists(self.processed_folder)\n",
    "        if not processed_folder_exists:\n",
    "            return False\n",
    "\n",
    "        return all(\n",
    "            check_integrity(os.path.join(self.processed_folder, file)) for file in (self.training_file, self.test_file)\n",
    "        )\n",
    "\n",
    "    def _load_legacy_data(self):\n",
    "        # This is for BC only. We no longer cache the data in a custom binary, but simply read from the raw data\n",
    "        # directly.\n",
    "        data_file = self.training_file if self.train else self.test_file\n",
    "        return torch.load(os.path.join(self.processed_folder, data_file))\n",
    "\n",
    "    def _load_data(self):\n",
    "        image_file = f\"{'train' if self.train else 't10k'}-images-idx3-ubyte\"\n",
    "        data = read_image_file(os.path.join(self.raw_folder, image_file))\n",
    "        #Technically, we do not even need the labels for now\n",
    "        # We just need the clean images of both types\n",
    "        randata = data[torch.randperm(data.shape[0]),:,:]\n",
    "        targets = (data, randata)\n",
    "        \n",
    "        \n",
    "        # Now do the ambiguation here\n",
    "        data = data + randata\n",
    "        return data, targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], (self.targets[0][index], self.targets[1][index])\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Imagedata[torch.randperm(data.shape[0]),:,:]\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "            \n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'processed')\n",
    "\n",
    "    @property\n",
    "    def class_to_idx(self):\n",
    "        return {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return all(\n",
    "            check_integrity(os.path.join(self.raw_folder, os.path.splitext(os.path.basename(url))[0]))\n",
    "            for url, _ in self.resources\n",
    "        )\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the MNIST data if it doesn't exist already.\"\"\"\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        os.makedirs(self.raw_folder, exist_ok=True)\n",
    "\n",
    "        # download files\n",
    "        for filename, md5 in self.resources:\n",
    "            for mirror in self.mirrors:\n",
    "                url = \"{}{}\".format(mirror, filename)\n",
    "                try:\n",
    "                    print(\"Downloading {}\".format(url))\n",
    "                    download_and_extract_archive(\n",
    "                        url, download_root=self.raw_folder,\n",
    "                        filename=filename,\n",
    "                        md5=md5\n",
    "                    )\n",
    "                except URLError as error:\n",
    "                    print(\n",
    "                        \"Failed to download (trying next):\\n{}\".format(error)\n",
    "                    )\n",
    "                    continue\n",
    "                finally:\n",
    "                    print()\n",
    "                break\n",
    "            else:\n",
    "                raise RuntimeError(\"Error downloading {}\".format(filename))\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-harbor",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "class Downsample(object):\n",
    "    def __init__(self, size=[1,196]):\n",
    "        self.size=size\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        img = np.squeeze(tensor)\n",
    "        m = torch.nn.AvgPool2d(2, stride=2)\n",
    "        return m(img.unsqueeze(0))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__+'({})'.format(self.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-french",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:137.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     Downsample()\n",
    "     ])\n",
    "mnist_superimposed = MNISTsuperimposed(\"./MNIST data/train\", train = True, download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-leisure",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "trainset = DataLoader(mnist_superimposed, batch_size=32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-jamaica",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "def show_images(dataset, training = True):\n",
    "    \n",
    "    fig = plt.figure(figsize = (20, 14))\n",
    "    rows = 3\n",
    "    columns = 4\n",
    "    j=0\n",
    "    for i in range(1,columns*rows+1):\n",
    "        if i >=1 and i< 5:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "\n",
    "            plt.imshow(dataset[i][0].squeeze(0))\n",
    "        if i >=5 and i < 9:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(dataset[i-4][1][0])\n",
    "        if i >= 9 and i<13:\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(dataset[i-8][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-pastor",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1008 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(mnist_superimposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-patent",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import Conv2d, ConvTranspose2d, Linear, Sequential, Flatten, ReLU, LeakyReLU, AvgPool2d, MaxPool2d,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-smile",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, inplace = False):\n",
    "        super(AE,self).__init__()\n",
    "        \n",
    "        self.Upsample_1 = nn.Sequential(\n",
    "            nn.Flatten(start_dim = 2),\n",
    "            nn.Linear(196, 256),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.Linear(512, 784),\n",
    "            nn.Linear(784, 784),\n",
    "            nn.ReLU(inplace),\n",
    "        )\n",
    "        \n",
    "            \n",
    "        self.initial_Processing = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 2, kernel_size = 3, padding = 1, stride = 1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 2, out_channels = 8, kernel_size = 3, padding =1, stride = 1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace),\n",
    "        )\n",
    "\n",
    "        self.Down_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 8, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Down_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.Down_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Down_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Up_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 1024, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 1024, out_channels = 1024, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 1024, out_channels = 512, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1024, out_channels = 512, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 512, out_channels = 256, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 256, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 256, out_channels = 128, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 128, out_channels = 64, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 64, out_channels = 2, kernel_size = (1, 1))\n",
    "        )\n",
    "        \n",
    "        self.Upsample_2 = nn.Sequential(\n",
    "            nn.Flatten(start_dim = 1),\n",
    "            nn.Linear(392, 512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(inplace),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.Linear(1024, 1568),\n",
    "            nn.Linear(1568, 1568),\n",
    "            nn.ReLU(inplace),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = self.Upsample_1(x)\n",
    "        output = output.reshape(32, 1, 28, 28)\n",
    "        \n",
    "        output = self.initial_Processing(output)\n",
    "        \n",
    "        output = self.Down_1(output)\n",
    "        output_1 = output\n",
    "        \n",
    "        \n",
    "        output = self.Down_2(output)\n",
    "        output_2 = output\n",
    "        \n",
    "        output = self.Down_3(output)\n",
    "        output_3 = output\n",
    "        \n",
    "        output = self.Down_4(output)\n",
    "        output_4 = output\n",
    "        \n",
    "        \n",
    "        output = self.Up_1(output)\n",
    "        diffY = output_4.size()[2] - output.size()[2]\n",
    "        diffX = output_4.size()[3] - output.size()[3]\n",
    "        output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        output = torch.cat([output_4, output], dim=1)\n",
    "\n",
    "\n",
    "        output = self.Up_2(output)\n",
    "        diffY = output_3.size()[2] - output.size()[2]\n",
    "        diffX = output_3.size()[3] - output.size()[3]\n",
    "        output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        output = torch.cat([output_3, output], dim=1)\n",
    "\n",
    "\n",
    "        output = self.Up_3(output)        \n",
    "        diffY = output_2.size()[2] - output.size()[2]\n",
    "        diffX = output_2.size()[3] - output.size()[3]\n",
    "        output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        output = torch.cat([output_2, output], dim=1)\n",
    "\n",
    "\n",
    "        output = self.Up_4(output)\n",
    "        diffY = output_1.size()[2] - output.size()[2]\n",
    "        diffX = output_1.size()[3] - output.size()[3]\n",
    "        output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        output = torch.cat([output_1, output], dim=1)\n",
    "\n",
    "\n",
    "        output = self.Up_5(output)\n",
    "\n",
    "        \n",
    "        output = self.Upsample_2(output)        \n",
    "        output = output.reshape(32, 2, 28, 28)\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-monthly",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "AEnet = AE().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-military",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(AEnet.parameters(), lr=0.0005)\n",
    "criterion = nn.MSELoss()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-software",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss per image: 298.520996\n",
      "[1,  1000] loss per image: 303.741272\n",
      "[1,  1500] loss per image: 292.902130\n",
      "[2,   500] loss per image: 275.121399\n",
      "[2,  1000] loss per image: 277.372803\n",
      "[2,  1500] loss per image: 256.789856\n",
      "[3,   500] loss per image: 249.934479\n",
      "[3,  1000] loss per image: 259.179626\n",
      "[3,  1500] loss per image: 238.752991\n",
      "[4,   500] loss per image: 230.726700\n",
      "[4,  1000] loss per image: 246.430664\n",
      "[4,  1500] loss per image: 226.561920\n",
      "[5,   500] loss per image: 222.688934\n",
      "[5,  1000] loss per image: 239.554993\n",
      "[5,  1500] loss per image: 221.647171\n",
      "[6,   500] loss per image: 219.251038\n",
      "[6,  1000] loss per image: 237.237747\n",
      "[6,  1500] loss per image: 217.850861\n",
      "[7,   500] loss per image: 215.118256\n",
      "[7,  1000] loss per image: 232.258820\n",
      "[7,  1500] loss per image: 214.542572\n",
      "[8,   500] loss per image: 214.476105\n",
      "[8,  1000] loss per image: 229.672089\n",
      "[8,  1500] loss per image: 212.188171\n",
      "[9,   500] loss per image: 210.242340\n",
      "[9,  1000] loss per image: 223.209518\n",
      "[9,  1500] loss per image: 209.708649\n",
      "[10,   500] loss per image: 207.668976\n",
      "[10,  1000] loss per image: 220.172592\n",
      "[10,  1500] loss per image: 207.828857\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10, 7))\n",
    "rows = 1\n",
    "columns = 5\n",
    "\n",
    "epochs = 100\n",
    "train_loss = []\n",
    "flag = True\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainset):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = AEnet(data[0].float().to(device))\n",
    "#         print(outputs.shape)\n",
    "# data[1][0].float().to(device), data[1][1].float().to(device)\n",
    "        \n",
    "        output_1 = outputs[:, :1, :, :]\n",
    "        output_2 = outputs[:, 1:, :, :]\n",
    "        loss = criterion(output_1.float().reshape(-1).to(device), data[1][0].reshape(-1).float().to(device)) + criterion(output_2.float().reshape(-1).to(device), data[1][1].reshape(-1).float().to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:\n",
    "            print('[%d, %5d] loss per image: %.6f' %\n",
    "                  (epoch + 1, i + 1, loss.item()/32))\n",
    "            if float(loss.item()/32) < float(100):\n",
    "                break\n",
    "            if epoch % 10 == 9:\n",
    "                torch.save(AEnet.state_dict(), \"./weights.pth\")\n",
    "                \n",
    "            \n",
    "\n",
    "            \n",
    "print(\"The lowest was: \", min(train_loss)/32)\n",
    "        \n",
    "print('Finished Training')\n",
    "flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-accessory",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "# m = nn.ReLU(inplace = True)\n",
    "# input = torch.randn(2).unsqueeze(0)\n",
    "# output = torch.cat((m(input),m(-input)))\n",
    "# print(output, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-rings",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "print(outputs[0].shape)\n",
    "plt.imshow(outputs[0][1,:,:].reshape(28,28).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-baseline",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(outputs[0][0,:,:].reshape(28,28).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-carrier",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(data[1][1][1].squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-probe",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(data[1][0][1].squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-burton",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "torch.save(AEnet.state_dict(), \"./weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-virtue",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "committed-variable",
   "metadata": {},
   "source": [
    "## Architectures ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-program",
   "metadata": {
    "gradient": {},
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, inplace = False):\n",
    "        super(AE,self, inplace).__init__()\n",
    "        \n",
    "        \n",
    "            \n",
    "        self.initial_Processing = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 4, kernel_size = 3, padding = 1, stride = 1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 4, out_channels = 4, kernel_size = 3, padding =1, stride = 1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace),\n",
    "        )\n",
    "\n",
    "        self.Down_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 4, out_channels = 8, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 8, out_channels = 8, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Down_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Down_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Down_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Down_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.Up_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 256, out_channels = 256, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 128, out_channels = 128, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 64, out_channels = 64, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 16, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 16, out_channels = 16, kernel_size = (2, 2))\n",
    "        )\n",
    "\n",
    "        self.Up_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 16, out_channels = 4, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.Conv2d(in_channels = 4, out_channels = 1, kernel_size = (3, 3), padding = 1, stride = 1),\n",
    "            nn.ReLU(inplace),\n",
    "            nn.ConvTranspose2d(in_channels = 1, out_channels = 1, kernel_size = (2, 2))\n",
    "        )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            output = self.initial_Processing(x)\n",
    "            output = self.Down_1(output)\n",
    "            output_1 = output\n",
    "            output = self.Down_2(output)\n",
    "            output_2 = output\n",
    "            output = self.Down_3(output)\n",
    "            output_3 = output\n",
    "            output = self.Down_4(output)\n",
    "            output_4 = output\n",
    "            \n",
    "            output = self.Up_1(output)\n",
    "            diffY = output_4.size()[2] - output.size()[2]\n",
    "            diffX = output_4.size()[3] - output.size()[3]\n",
    "            output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                            diffY // 2, diffY - diffY // 2])\n",
    "            output = torch.cat([output_4, output], dim=1)\n",
    "            \n",
    "            \n",
    "            output = self.Up_2(output)\n",
    "            diffY = output_4.size()[2] - output.size()[2]\n",
    "            diffX = output_4.size()[3] - output.size()[3]\n",
    "            output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                            diffY // 2, diffY - diffY // 2])\n",
    "            output = torch.cat([output_4, output], dim=1)\n",
    "            \n",
    "            \n",
    "            output = self.Up_3(output)\n",
    "            diffY = output_4.size()[2] - output.size()[2]\n",
    "            diffX = output_4.size()[3] - output.size()[3]\n",
    "            output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                            diffY // 2, diffY - diffY // 2])\n",
    "            output = torch.cat([output_4, output], dim=1)\n",
    "            \n",
    "            \n",
    "            output = self.Up_4(output)\n",
    "            diffY = output_4.size()[2] - output.size()[2]\n",
    "            diffX = output_4.size()[3] - output.size()[3]\n",
    "            output = F.pad(output, [diffX // 2, diffX - diffX // 2,\n",
    "                            diffY // 2, diffY - diffY // 2])\n",
    "            output = torch.cat([output_4, output], dim=1)\n",
    "            \n",
    "            \n",
    "            output = self.Up_5(output)\n",
    "            \n",
    "            print(output.shape)\n",
    "            \n",
    "        \n",
    "            return outputa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-prison",
   "metadata": {
    "gradient": {},
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from pdb import set_trace\n",
    "# class AE(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(AE,self).__init__()   \n",
    "        \n",
    "#         self.Encoder_1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 4, kernel_size = 3, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(4, 16, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.Conv2d(16, 64, kernel_size = 9, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(64, 64, kernel_size = 7, padding = 3, stride = 1),\n",
    "            \n",
    "#             nn.Conv2d(64, 256, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.Conv2d(256, 512, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(512, 512, kernel_size = 3, padding = 1, stride = 1),\n",
    "            \n",
    "#             nn.Conv2d(512, 128, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Dropout(p = 0.30),\n",
    "#             nn.Conv2d(128, 32, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(32, 8, kernel_size = 7, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(8, 4, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(4, 4, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "        \n",
    "#         self.Decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(4, 16, kernel_size = 7, padding = 1, stride = 2),\n",
    "#             nn.ConvTranspose2d(16, 128, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.ConvTranspose2d(128, 512, kernel_size = 4, padding = 1, stride = 1),\n",
    "#             nn.ConvTranspose2d(512, 512, kernel_size = 5, padding = 2, stride = 1),\n",
    "            \n",
    "#             nn.ConvTranspose2d(512, 128, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.ConvTranspose2d(128, 64, kernel_size = 3, padding = 1, stride = 1),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.ConvTranspose2d(64, 32, kernel_size = 5, padding = 1, stride = 2),\n",
    "#             nn.ConvTranspose2d(32, 32, kernel_size = 5, padding = 2, stride = 1),\n",
    "            \n",
    "#             nn.ConvTranspose2d(32, 16, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.ConvTranspose2d(16, 4, kernel_size = 4, padding = 1, stride = 1),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.ConvTranspose2d(4, 1, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.ConvTranspose2d(1, 1, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.Linear_2 = nn.Sequential(\n",
    "#             nn.Linear(1296, 1536),\n",
    "#             nn.Linear(1536, 2048),\n",
    "#             nn.Linear(2048, 2048),\n",
    "            \n",
    "#             nn.Linear(2048, 1024),\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.Linear(256, 256),\n",
    "            \n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.Linear(128, 32),\n",
    "#             nn.Linear(32, 1024),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.Linear(1024, 1296),\n",
    "#             nn.Linear(1296, 1296),\n",
    "#             nn.LeakyReLU(),\n",
    "#         )\n",
    "        \n",
    "#         self.Encoder_2 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 2, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(2, 8, kernel_size = 7, padding = 2, stride = 1),\n",
    "#             nn.Conv2d(8, 16, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(16, 16, kernel_size = 7, padding = 3, stride = 1),\n",
    "            \n",
    "#             nn.Conv2d(16, 32, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(32, 64, kernel_size = 9, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(64, 64, kernel_size = 3, padding = 1, stride = 1),\n",
    "            \n",
    "#             nn.Conv2d(64, 8, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.Conv2d(8, 2, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#     def forward(self,x):\n",
    "        \n",
    "#         #Step 1\n",
    "#         output = self.Encoder_1(x)\n",
    "        \n",
    "#         #Step 2\n",
    "        \n",
    "#         output = self.Decoder(output)\n",
    "        \n",
    "#         print(output.shape)\n",
    "        \n",
    "#         #Step 3\n",
    "        \n",
    "# #         output = torch.flatten(output, 2)\n",
    "        \n",
    "# #         output = self.Linear_2(output)\n",
    "        \n",
    "#         #Step 4\n",
    "        \n",
    "# #         output = output.reshape(32, 1, 36, 36)\n",
    "        \n",
    "#         output = self.Encoder_2(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "# #         print(output.shape)\n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-position",
   "metadata": {
    "gradient": {},
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from pdb import set_trace\n",
    "# class AE(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(AE,self).__init__()   \n",
    "        \n",
    "#         self.Encoder_1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 4, kernel_size = 3, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(4, 16, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.Conv2d(16, 64, kernel_size = 9, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(64, 64, kernel_size = 7, padding = 3, stride = 1),\n",
    "            \n",
    "#             nn.Conv2d(64, 256, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.Conv2d(256, 512, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(512, 512, kernel_size = 3, padding = 1, stride = 1),\n",
    "            \n",
    "#             nn.Conv2d(512, 128, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Dropout(p = 0.30),\n",
    "#             nn.Conv2d(128, 32, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(32, 8, kernel_size = 7, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(8, 4, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(4, 4, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "        \n",
    "#         self.Decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(4, 16, kernel_size = 7, padding = 1, stride = 2),\n",
    "#             nn.ConvTranspose2d(16, 128, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.ConvTranspose2d(128, 512, kernel_size = 4, padding = 1, stride = 1),\n",
    "#             nn.ConvTranspose2d(512, 512, kernel_size = 5, padding = 2, stride = 1),\n",
    "            \n",
    "#             nn.ConvTranspose2d(512, 128, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.ConvTranspose2d(128, 64, kernel_size = 3, padding = 1, stride = 1),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.ConvTranspose2d(64, 32, kernel_size = 5, padding = 1, stride = 2),\n",
    "#             nn.ConvTranspose2d(32, 32, kernel_size = 5, padding = 2, stride = 1),\n",
    "            \n",
    "#             nn.ConvTranspose2d(32, 16, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.ConvTranspose2d(16, 4, kernel_size = 4, padding = 1, stride = 1),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.ConvTranspose2d(4, 1, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.ConvTranspose2d(1, 1, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.Linear_2 = nn.Sequential(\n",
    "#             nn.Linear(1296, 1536),\n",
    "#             nn.Linear(1536, 2048),\n",
    "#             nn.Linear(2048, 2048),\n",
    "            \n",
    "#             nn.Linear(2048, 1024),\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.Linear(256, 256),\n",
    "            \n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.Linear(128, 32),\n",
    "#             nn.Linear(32, 1024),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.Linear(1024, 1296),\n",
    "#             nn.Linear(1296, 1296),\n",
    "#             nn.LeakyReLU(),\n",
    "#         )\n",
    "        \n",
    "#         self.Encoder_2 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 2, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(2, 8, kernel_size = 7, padding = 2, stride = 1),\n",
    "#             nn.Conv2d(8, 16, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(16, 16, kernel_size = 7, padding = 3, stride = 1),\n",
    "            \n",
    "#             nn.Conv2d(16, 32, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(32, 64, kernel_size = 9, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(64, 64, kernel_size = 3, padding = 1, stride = 1),\n",
    "            \n",
    "#             nn.Conv2d(64, 8, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.Conv2d(8, 2, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#     def forward(self,x):\n",
    "        \n",
    "#         #Step 1\n",
    "#         output = self.Encoder_1(x)\n",
    "        \n",
    "#         #Step 2\n",
    "        \n",
    "#         output = self.Decoder(output)\n",
    "        \n",
    "#         print(output.shape)\n",
    "        \n",
    "#         #Step 3\n",
    "        \n",
    "# #         output = torch.flatten(output, 2)\n",
    "        \n",
    "# #         output = self.Linear_2(output)\n",
    "        \n",
    "#         #Step 4\n",
    "        \n",
    "# #         output = output.reshape(32, 1, 36, 36)\n",
    "        \n",
    "#         output = self.Encoder_2(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "# #         print(output.shape)\n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-barrel",
   "metadata": {
    "gradient": {},
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from pdb import set_trace\n",
    "# class AE(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(AE,self).__init__()\n",
    "        \n",
    "\n",
    "#         self.Encoder_1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 4, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(4, 4, kernel_size = 9, padding = 4, stride = 1),\n",
    "#             nn.Conv2d(4, 16, kernel_size = 7, padding = 2, stride = 1),\n",
    "#             nn.Conv2d(16, 16, kernel_size = 9, padding = 4, stride = 1),\n",
    "\n",
    "#             nn.Conv2d(16, 64, kernel_size = 9, padding = 3, stride = 1),\n",
    "#             nn.Conv2d(64, 128, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "#             nn.Conv2d(128, 64, kernel_size = 5, padding = 1, stride = 1),\n",
    "\n",
    "#             nn.Conv2d(64, 32, kernel_size = 3, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(32, 8, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(8, 8, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.Conv2d(8, 1, kernel_size = 3, padding = 1, stride = 1),\n",
    "#             nn.Conv2d(1, 1, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.ReLU(),\n",
    "\n",
    "#         )\n",
    "\n",
    "        \n",
    "# #         self.Linear_1 = nn.Sequential(\n",
    "# #             nn.Flatten(start_dim = 2),\n",
    "# #             nn.Linear(16, 784),\n",
    "# #             nn.Linear(784, 392),\n",
    "# #             nn.Linear(392, 196),\n",
    "# #             nn.Dropout(p = 0.25),\n",
    "# #             nn.Linear(196, 196),\n",
    "# #             nn.Linear(196, 98),\n",
    "\n",
    "# #             nn.Linear(98, 56),\n",
    "# #             nn.Linear(56, 56),\n",
    "# #             nn.Dropout(p = 0.1),\n",
    "# #             nn.Linear(56, 49),\n",
    "# #             nn.Linear(49, 392),\n",
    "\n",
    "# #             nn.Linear(392, 28),\n",
    "# #             nn.Linear(28, 784),\n",
    "# #             nn.Linear(784, 784),\n",
    "# #             nn.LeakyReLU(),\n",
    "\n",
    "# #         )\n",
    "        \n",
    "        \n",
    "\n",
    "#         self.Decoder_1 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(1, 2, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.ConvTranspose2d(2, 4, kernel_size = 3, padding = 1, stride = 1),\n",
    "#             nn.ConvTranspose2d(4, 8, kernel_size = 5, padding = 1, stride = 2),\n",
    "#             nn.ConvTranspose2d(8, 8, kernel_size = 5, padding = 2, stride = 1),\n",
    "            \n",
    "\n",
    "#             nn.ConvTranspose2d(8, 16, kernel_size = 5, padding = 1, stride = 1),\n",
    "#             nn.ConvTranspose2d(16, 32, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.ConvTranspose2d(32, 64, kernel_size = 7, padding = 1, stride = 2),\n",
    "#             nn.ConvTranspose2d(64, 64, kernel_size = 7, padding = 3, stride = 1),\n",
    "#             nn.Dropout(p = 0.25),\n",
    "\n",
    "#             nn.ConvTranspose2d(64, 128, kernel_size= 7, padding = 3, stride = 1),\n",
    "#             nn.Dropout(p = 0.33),\n",
    "#             nn.ConvTranspose2d(128, 256, kernel_size = 7, padding = 1, stride = 1),\n",
    "#             nn.ConvTranspose2d(256, 512, kernel_size= 5, padding = 2, stride = 1),\n",
    "#             nn.ConvTranspose2d(512, 128, kernel_size = 5, padding = 2, stride = 1),\n",
    "#             nn.ConvTranspose2d(128, 64, kernel_size= 3, padding = 1, stride = 1),\n",
    "#             nn.ConvTranspose2d(64, 4, kernel_size = 4, padding = 2, stride = 1),\n",
    "#             nn.ConvTranspose2d(4, 1, kernel_size= 7, padding = 3, stride = 1),\n",
    "#             nn.ConvTranspose2d(1, 2, kernel_size = 3, padding = 1, stride = 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Flatten(start_dim = 2),\n",
    "#         )\n",
    "\n",
    "\n",
    "#         self.Linear_2 = nn.Sequential(\n",
    "#             nn.Linear(1568, 784),\n",
    "#             nn.Linear(784, 392),\n",
    "#             nn.Linear(392, 196),\n",
    "#             nn.Linear(196, 196),\n",
    "#             nn.Linear(196, 98),\n",
    "\n",
    "#             nn.Linear(98, 56),\n",
    "#             nn.Linear(56, 56),\n",
    "#             nn.Linear(56, 49),\n",
    "#             nn.Linear(49, 392),\n",
    "\n",
    "#             nn.Linear(392, 28),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Linear(28, 784),\n",
    "#             nn.Linear(784, 1568),\n",
    "#             nn.LeakyReLU(),\n",
    "\n",
    "#         )\n",
    "        \n",
    "\n",
    "# #         self.Encoder_2 = nn.Sequential(\n",
    "# #             nn.Conv2d(2, 4, kernel_size = 5, padding = 2, stride = 1),\n",
    "# #             nn.Conv2d(4, 64, kernel_size = 7, padding = 3, stride = 1),\n",
    "# #             nn.Conv2d(64, 64, kernel_size = 5, padding = 2, stride = 1),\n",
    "# #             nn.Conv2d(64, 128, kernel_size = 7, padding = 3, stride = 1),\n",
    "\n",
    "# #             nn.Conv2d(128, 512, kernel_size = 7, padding = 3, stride = 1),\n",
    "# #             nn.Conv2d(512, 512, kernel_size = 9, padding = 4, stride = 1),\n",
    "# #             nn.Conv2d(512, 64, kernel_size = 3, padding = 1, stride = 1),\n",
    "\n",
    "# #             nn.Conv2d(64, 2, kernel_size = 5, padding = 2, stride = 1),\n",
    "# #             nn.Conv2d(2, 2, kernel_size = 7, padding = 3, stride = 1),\n",
    "# #             nn.ReLU(),\n",
    "# #         )\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#     def forward(self,x):\n",
    "        \n",
    "#         output = self.Encoder_1(x)\n",
    "        \n",
    "# #         print(output.shape)\n",
    "        \n",
    "# #         output = self.Linear_1(output)\n",
    "        \n",
    "# #         output = output.reshape(32, 1, 28, 28)\n",
    "        \n",
    "#         output = self.Decoder_1(output)\n",
    "        \n",
    "#         output = output.reshape(32, 1, 1568)\n",
    "        \n",
    "#         output = self.Linear_2(output)\n",
    "        \n",
    "#         output = output.reshape(32, 2, 28, 28)\n",
    "# #         output = self.Encoder_2(output)\n",
    "        \n",
    "# #         print(output.shape)\n",
    "        \n",
    "#         return output\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
